# yt-transcript

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

---

## English

Transcribe YouTube videos into formatted Markdown articles. Supports subtitle download or Deepgram speech-to-text (with multi-speaker recognition).

### âœ¨ Features

- ğŸ¯ **Smart Subtitle Fetching**: Prioritizes YouTube official/auto-generated subtitles
- ğŸ™ï¸ **Speech-to-Text**: Auto-transcribes via Deepgram Nova-2 when no subtitles available
- ğŸ‘¥ **Multi-speaker Recognition**: Automatically distinguishes different speakers
- ğŸŒ **Bilingual Support**: Auto-translate and side-by-side formatting
- ğŸ¤– **AI Enhancement**: Auto punctuation, paragraph splitting, error correction
- ğŸ“ **Markdown Output**: Formatted articles with metadata

### ğŸ“‹ Prerequisites

- `yt-dlp`: Download YouTube videos/audio/subtitles
- `ffmpeg`: Audio processing (splitting, silence detection)
- `python3`: Text processing
- `curl`: Call Deepgram API
- [Deepgram Account](https://console.deepgram.com/): For speech transcription

#### Installation

```bash
# macOS
brew install yt-dlp python3 ffmpeg

# or via pip
pip install yt-dlp
```

### âš™ï¸ Configuration

1. Copy the config template:
   ```bash
   cp config.example.yaml config.yaml
   ```

2. Edit `config.yaml` with your settings:
   ```yaml
   deepgram_api_key: "your_api_key_here"
   output_dir: "~/Downloads"
   ```

### ğŸš€ Usage

#### As a Claude Skill

1. Place this directory in `~/.claude/skills/` or your Claude skills directory
2. Provide a YouTube link in your Claude conversation
3. Claude will automatically execute the transcription workflow

#### Single Video Example

```
Please transcribe this video: https://www.youtube.com/watch?v=xxxxx
```

#### Multiple Videos (Batch Processing)

You can provide multiple links at once. They will be processed **serially** (one at a time) to ensure quality and context isolation:

```
Please transcribe these videos:
- https://www.youtube.com/watch?v=xxxxx
- https://www.youtube.com/watch?v=yyyyy
- https://www.youtube.com/watch?v=zzzzz
```

After completion, a summary table will be provided with status and output paths for each video.

### ğŸ“ Project Structure

```
yt-transcript/
â”œâ”€â”€ SKILL.md                 # Claude Skill workflow guide (main entry point)
â”œâ”€â”€ workflows/               # Modular workflow files
â”œâ”€â”€ prompts/                 # Single-task prompt templates
â”œâ”€â”€ scripts/                 # Helper shell scripts
â”œâ”€â”€ yt_transcript_utils.py   # Python utilities
â”œâ”€â”€ config.yaml              # Local config (gitignored)
â”œâ”€â”€ config.example.yaml      # Config template
â””â”€â”€ README.md                # This document
```

### ğŸ—ï¸ Architecture & Design Philosophy (v4.0)

> **Design Goal**: Enable highly reliable execution on **Weak Models** (e.g., 8B parameters) while maintaining advanced capabilities for SOTA models.

#### 1. The "Weak Model" Challenge

We identified three primary failure modes when running complex agentic skills on smaller models (Llama-3-8B, Gemini Flash, etc.):

1.  **Context Overflow**: Loading a 800+ line `SKILL.md` plus conversation history dilutes attention.
2.  **Instruction Interference**: When a prompt contains >3 distinct objectives (e.g., "Translate AND Format AND Fix Grammar"), weak models tend to ignore the secondary constraints.
3.  **State Amnesia**: During multi-step workflows, weak models often lose track of variable state (`VIDEO_ID`, `LANGUAGE`) after context switching.

#### 2. Core Design Patterns

To address these, we implemented the following patterns:

**2.1 Modular Context Loading (The "Swap" Pattern)**
Instead of a monolithic instruction file, we split the skill into a lightweight router and specialized modules.

*   **Router (`SKILL.md`)**: < 400 lines. Contains only high-level decision trees (Binary choices: Yes/No).
*   **Modules (`workflows/*.md`)**: Loaded *on-demand*. The model never sees the "Subtitle Download" instructions while doing "Text Optimization".

*Impact: Reduces active context by ~40-50%.*

**2.2 Single-Task Prompts**
We enforce a hard rule: **One Prompt = One Primary Objective**.

*   `structure_only.md`: Only adds newlines and headers. explicit instruction to NOT translate.
*   `translate_only.md`: Only translates. Explicit instruction to preserve structure.
*   `quick_cleanup.md`: Only adds punctuation.

*Impact: Drastically reduces "hallucination" and instruction skipping.*

**2.3 The "Context Recap" Handshake**
Every workflow file begins with a **Variable Confirmation Section** that forces the model to "ground" itself before executing new instructions, combating state amnesia.

**2.4 Fail-Fast & "Safety Nets"**
Weak models tend to loop indefinitely when errors occur.
*   **Fail-Fast**: Instructions explicitly say "If step X fails, STOP. Do not retry."
*   **Safety Net**: In `quick_cleanup.md`, we added a trigger: "If text has ZERO punctuation, ignore minimal-change rules and fully punctuate."

#### 3. Directory Structure Role

```
yt-transcript/
â”œâ”€â”€ SKILL.md                # The Brain (Router)
â”œâ”€â”€ workflows/              # The Limbs (Procedural Knowledge)
â”‚   â”œâ”€â”€ subtitle_download.md
â”‚   â”œâ”€â”€ deepgram_transcribe.md
â”‚   â””â”€â”€ text_optimization.md
â”œâ”€â”€ prompts/                # The Voice (Generation Templates)
â”‚   â”œâ”€â”€ structure_only.md
â”‚   â”œâ”€â”€ translate_only.md
â”‚   â””â”€â”€ quick_cleanup.md
â”œâ”€â”€ scripts/                # The Hands (Tool Execution)
â”‚   â”œâ”€â”€ preflight.sh
â”‚   â”œâ”€â”€ download.sh
â”‚   â””â”€â”€ cleanup.sh
â””â”€â”€ yt_transcript_utils.py  # Python Utilities
```

#### 4. Minimum Requirements

*   **Context**: 4k tokens active window
*   **Reasoning**: Elementary (Binary classification)
*   **Instruction Following**: Medium (Single-constraint following)
*   **Target Model Tier**: Llama-3-8B (Instruct) / GPT-3.5 Turbo level.

#### Audio Splitting Strategy

To bypass API limits (25MB) and improve reliability, large audio files are split intelligently:
1. **Rough Split**: Calculate theoretical split points at 10MB intervals.
2. **Silence Detection**: Use FFmpeg to find silence intervals near rough split points.
3. **Smart Decision**: Choose the nearest silence point within 60s deviation.
4. **Fallback**: If no silence is found, force split at the rough point.

#### Long-Text Processing Strategy (New!)

To handle arbitrarily long videos (e.g., >2 hours) without hitting LLM context limits, we use a **Map-Reduce inspired hybrid pipeline**:

1.  **Structural Chunking (Script)**:
    - The `chunk-text` command splits raw text into semantic chunks (~8000 chars) based on sentence boundaries.
    - Uses an idempotent `manifest.json` to track processing status, allowing resumability.

2.  **Two-Stage Chapter Planning**:
    - **Priority 1**: Use YouTube Chapters if available (via `get-chapters`).
    - **Priority 2**: If no chapters, the LLM first generates summaries for each chunk, then plans a global chapter structure based on summaries.

3.  **Stateless Translation**:
    - Each chunk is translated independently by the LLM without needing global context.
    - Script (`merge-content`) handles the re-assembly and injection of chapter headers.

#### Why Serial Processing for Multiple Links?

When processing multiple YouTube links, this skill uses **serial processing** (one video at a time) instead of parallel:

| Approach | Feasibility | Reason |
|----------|-------------|--------|
| Parallel with Subagents | Not supported | Current Claude/Gemini Code architecture does not support spawning independent subagents with isolated context for general tasks |
| Parallel in single session | Not feasible | AI optimization step requires direct LLM involvement; cannot split into multiple parallel cognitive threads |
| Serial processing | Adopted | Process one video completely, clear context, then proceed to next |

### ğŸ“„ License

MIT License

### ğŸ”— Links

- [Deepgram API Docs](https://developers.deepgram.com/)
- [yt-dlp Project](https://github.com/yt-dlp/yt-dlp)

---

## ä¸­æ–‡

å°† YouTube è§†é¢‘è½¬å½•ä¸ºæ ¼å¼åŒ–çš„ Markdown æ–‡ç« ã€‚æ”¯æŒå­—å¹•ä¸‹è½½æˆ– Deepgram è¯­éŸ³è½¬å½•ï¼ˆåŒ…å«å¤šè§’è‰²è¯†åˆ«ï¼‰ã€‚

### âœ¨ åŠŸèƒ½ç‰¹ç‚¹

- ğŸ¯ **æ™ºèƒ½å­—å¹•è·å–**ï¼šä¼˜å…ˆä½¿ç”¨ YouTube å®˜æ–¹/è‡ªåŠ¨å­—å¹•
- ğŸ™ï¸ **è¯­éŸ³è½¬å½•**ï¼šæ— å­—å¹•æ—¶è‡ªåŠ¨ä½¿ç”¨ Deepgram Nova-2 è½¬å½•
- ğŸ‘¥ **å¤šè¯´è¯è€…è¯†åˆ«**ï¼šè‡ªåŠ¨åŒºåˆ†ä¸åŒè®²è€…
- ğŸŒ **ä¸­è‹±åŒè¯­æ”¯æŒ**ï¼šè‡ªåŠ¨ç¿»è¯‘å¹¶å¯¹ç…§æ’ç‰ˆ
- ğŸ¤– **AI æ™ºèƒ½ä¼˜åŒ–**ï¼šè‡ªåŠ¨æ·»åŠ æ ‡ç‚¹ã€åˆ†æ®µã€çº é”™
- ğŸ“ **Markdown è¾“å‡º**ï¼šå¸¦å…ƒæ•°æ®çš„æ ¼å¼åŒ–æ–‡ç« 

### ğŸ“‹ å‰ç½®ä¾èµ–

- `yt-dlp`ï¼šä¸‹è½½ YouTube è§†é¢‘/éŸ³é¢‘/å­—å¹•
- `ffmpeg`ï¼šéŸ³é¢‘å¤„ç†ï¼ˆåˆ†å‰²ã€é™éŸ³æ£€æµ‹ï¼‰
- `python3`ï¼šå¤„ç†æ–‡æœ¬æ ¼å¼åŒ–
- `curl`ï¼šè°ƒç”¨ Deepgram API
- [Deepgram è´¦å·](https://console.deepgram.com/)ï¼šç”¨äºè¯­éŸ³è½¬å½•

#### å®‰è£…ä¾èµ–

```bash
# macOS
brew install yt-dlp python3 ffmpeg

# æˆ–ä½¿ç”¨ pip
pip install yt-dlp
```

### âš™ï¸ é…ç½®

1. å¤åˆ¶é…ç½®æ¨¡æ¿ï¼š
   ```bash
   cp config.example.yaml config.yaml
   ```

2. ç¼–è¾‘ `config.yaml`ï¼Œå¡«å…¥ä½ çš„é…ç½®ï¼š
   ```yaml
   deepgram_api_key: "your_api_key_here"
   output_dir: "~/Downloads"
   ```

### ğŸš€ ä½¿ç”¨æ–¹æ³•

#### ä½œä¸º Claude Skill ä½¿ç”¨

1. å°†æ­¤ç›®å½•æ”¾å…¥ `~/.claude/skills/` æˆ–ä½ çš„ Claude skills ç›®å½•
2. åœ¨ Claude å¯¹è¯ä¸­æä¾› YouTube é“¾æ¥
3. Claude å°†è‡ªåŠ¨æ‰§è¡Œè½¬å½•æµç¨‹

#### å•ä¸ªè§†é¢‘ç¤ºä¾‹

```
è¯·å¸®æˆ‘è½¬å½•è¿™ä¸ªè§†é¢‘ï¼šhttps://www.youtube.com/watch?v=xxxxx
```

#### å¤šä¸ªè§†é¢‘ï¼ˆæ‰¹é‡å¤„ç†ï¼‰

å¯ä»¥ä¸€æ¬¡æä¾›å¤šä¸ªé“¾æ¥ï¼Œå°†**ä¸²è¡Œå¤„ç†**ï¼ˆé€ä¸ªå¤„ç†ï¼‰ä»¥ç¡®ä¿è´¨é‡å’Œä¸Šä¸‹æ–‡éš”ç¦»ï¼š

```
è¯·å¸®æˆ‘è½¬å½•è¿™äº›è§†é¢‘ï¼š
- https://www.youtube.com/watch?v=xxxxx
- https://www.youtube.com/watch?v=yyyyy
- https://www.youtube.com/watch?v=zzzzz
```

å¤„ç†å®Œæˆåä¼šæä¾›æ±‡æ€»è¡¨æ ¼ï¼Œæ˜¾ç¤ºæ¯ä¸ªè§†é¢‘çš„çŠ¶æ€å’Œè¾“å‡ºè·¯å¾„ã€‚

### ğŸ“ é¡¹ç›®ç»“æ„

```
yt-transcript/
â”œâ”€â”€ SKILL.md                 # Claude Skill å·¥ä½œæµç¨‹æŒ‡å—ï¼ˆä¸»å…¥å£ï¼‰
â”œâ”€â”€ workflows/               # æ¨¡å—åŒ–å·¥ä½œæµæ–‡ä»¶
â”œâ”€â”€ prompts/                 # å•ä»»åŠ¡ Prompt æ¨¡æ¿
â”œâ”€â”€ scripts/                 # Shell è¾…åŠ©è„šæœ¬
â”œâ”€â”€ yt_transcript_utils.py   # Python å·¥å…·è„šæœ¬
â”œâ”€â”€ config.yaml              # æœ¬åœ°é…ç½®ï¼ˆå·² gitignoreï¼‰
â”œâ”€â”€ config.example.yaml      # é…ç½®æ¨¡æ¿
â””â”€â”€ README.md                # æœ¬æ–‡æ¡£
```

### ğŸ—ï¸ æ¶æ„è®¾è®¡ä¸è®¾è®¡å“²å­¦ (v4.0)

> **è®¾è®¡ç›®æ ‡**: ä½¿ Skill èƒ½å¤Ÿåœ¨ **å¼±æ¨¡å‹**ï¼ˆå¦‚ 8B å‚æ•°ï¼‰ä¸Šé«˜åº¦å¯é åœ°è¿è¡Œï¼ŒåŒæ—¶ä¸º SOTA æ¨¡å‹ä¿ç•™é«˜çº§èƒ½åŠ›ã€‚

#### 1. "å¼±æ¨¡å‹"çš„æŒ‘æˆ˜

æˆ‘ä»¬åœ¨è¾ƒå°æ¨¡å‹ï¼ˆLlama-3-8B, Gemini Flash ç­‰ï¼‰ä¸Šè¿è¡Œå¤æ‚çš„ Agent Skill æ—¶ï¼Œè¯†åˆ«å‡ºä¸‰ç§ä¸»è¦æ•…éšœæ¨¡å¼ï¼š

1.  **ä¸Šä¸‹æ–‡æº¢å‡º (Context Overflow)**: åŠ è½½ 800+ è¡Œçš„ `SKILL.md` åŠ ä¸Šå¯¹è¯å†å²ä¼šç¨€é‡Šæ¨¡å‹çš„æ³¨æ„åŠ›ã€‚
2.  **æŒ‡ä»¤å¹²æ‰° (Instruction Interference)**: å½“ä¸€ä¸ª Prompt åŒ…å« >3 ä¸ªä¸åŒçš„ç›®æ ‡ï¼ˆä¾‹å¦‚â€œç¿»è¯‘â€ä¸”â€œæ ¼å¼åŒ–â€ä¸”â€œä¿®å¤è¯­æ³•â€ï¼‰æ—¶ï¼Œå¼±æ¨¡å‹å€¾å‘äºå¿½ç•¥æ¬¡è¦çº¦æŸã€‚
3.  **çŠ¶æ€å¤±å¿† (State Amnesia)**: åœ¨å¤šæ­¥éª¤å·¥ä½œæµä¸­ï¼Œå¼±æ¨¡å‹åœ¨åˆ‡æ¢ä¸Šä¸‹æ–‡åç»å¸¸ä¸¢å¤±å˜é‡çŠ¶æ€ï¼ˆå¦‚ `VIDEO_ID`, `LANGUAGE`ï¼‰ã€‚

#### 2. æ ¸å¿ƒè®¾è®¡æ¨¡å¼

ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å®æ–½äº†ä»¥ä¸‹æ¨¡å¼ï¼š

**2.1 æ¨¡å—åŒ–ä¸Šä¸‹æ–‡åŠ è½½ ("Swap" Pattern)**
æˆ‘ä»¬å°† Skill æ‹†åˆ†ä¸ºä¸€ä¸ªè½»é‡çº§çš„è·¯ç”±ï¼ˆRouterï¼‰å’Œä¸“é—¨çš„æ¨¡å—ï¼ˆModulesï¼‰ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å•ä½“ç°æˆæ–‡ä»¶ã€‚

*   **Router (`SKILL.md`)**: < 400 è¡Œã€‚ä»…åŒ…å«é«˜çº§å†³ç­–æ ‘ï¼ˆäºŒå…ƒé€‰æ‹©ï¼šæ˜¯/å¦ï¼‰ã€‚
*   **Modules (`workflows/*.md`)**: *æŒ‰éœ€*åŠ è½½ã€‚æ¨¡å‹åœ¨æ‰§è¡Œâ€œæ–‡æœ¬ä¼˜åŒ–â€æ—¶æ°¸è¿œä¸ä¼šçœ‹åˆ°â€œå­—å¹•ä¸‹è½½â€çš„æŒ‡ä»¤ã€‚

*å½±å“ï¼šå‡å°‘çº¦ 40-50% çš„æ´»è·ƒä¸Šä¸‹æ–‡ã€‚*

**2.2 å•ä»»åŠ¡ Prompts**
æˆ‘ä»¬å¼ºåˆ¶æ‰§è¡Œä¸€æ¡ç¡¬æ€§è§„åˆ™ï¼š**ä¸€ä¸ª Prompt = ä¸€ä¸ªä¸»è¦ç›®æ ‡**ã€‚

*   `structure_only.md`: ä»…æ·»åŠ æ¢è¡Œå’Œæ ‡é¢˜ã€‚æ˜¾å¼æŒ‡ä»¤**ä¸**ç¿»è¯‘ã€‚
*   `translate_only.md`: ä»…ç¿»è¯‘ã€‚æ˜¾å¼æŒ‡ä»¤ä¿ç•™ç»“æ„ã€‚
*   `quick_cleanup.md`: ä»…æ·»åŠ æ ‡ç‚¹ã€‚

*å½±å“ï¼šå¤§å¹…å‡å°‘â€œå¹»è§‰â€å’ŒæŒ‡ä»¤è·³è¿‡ã€‚*

**2.3 "Context Recap" æ¡æ‰‹**
æ¯ä¸ª Workflow æ–‡ä»¶éƒ½ä»¥ **å˜é‡ç¡®è®¤éƒ¨åˆ†** å¼€å¤´ï¼Œå¼ºåˆ¶æ¨¡å‹åœ¨æ‰§è¡Œæ–°æŒ‡ä»¤å‰å…ˆâ€œè½åœ°â€è‡ªèº«çŠ¶æ€ï¼Œä»¥å¯¹æŠ—çŠ¶æ€å¤±å¿†ã€‚

**2.4 Fail-Fast & "å®‰å…¨ç½‘"**
å¼±æ¨¡å‹åœ¨å‡ºé”™æ—¶å€¾å‘äºæ— é™å¾ªç¯ã€‚
*   **Fail-Fast**: æŒ‡ä»¤æ˜¾å¼è¯´æ˜ "å¦‚æœæ­¥éª¤ X å¤±è´¥ï¼Œåœæ­¢ (STOP)ã€‚ä¸è¦é‡è¯•ã€‚"
*   **Safety Net**: åœ¨ `quick_cleanup.md` ä¸­ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªè§¦å‘å™¨ï¼š"å¦‚æœæ–‡æœ¬åŒ…å«é›¶æ ‡ç‚¹ï¼Œå¿½ç•¥æœ€å°ä¿®æ”¹è§„åˆ™å¹¶å®Œå…¨æ·»åŠ æ ‡ç‚¹ã€‚"

#### 3. ç›®å½•ç»“æ„è§’è‰²

```
yt-transcript/
â”œâ”€â”€ SKILL.md                # å¤§è„‘ (è·¯ç”±)
â”œâ”€â”€ workflows/              # å››è‚¢ (è¿‡ç¨‹çŸ¥è¯†)
â”‚   â”œâ”€â”€ subtitle_download.md
â”‚   â”œâ”€â”€ deepgram_transcribe.md
â”‚   â””â”€â”€ text_optimization.md
â”œâ”€â”€ prompts/                # å£°éŸ³ (ç”Ÿæˆæ¨¡æ¿)
â”‚   â”œâ”€â”€ structure_only.md
â”‚   â”œâ”€â”€ translate_only.md
â”‚   â””â”€â”€ quick_cleanup.md
â”œâ”€â”€ scripts/                # åŒæ‰‹ (å·¥å…·æ‰§è¡Œ)
â”‚   â”œâ”€â”€ preflight.sh
â”‚   â”œâ”€â”€ download.sh
â”‚   â””â”€â”€ cleanup.sh
â””â”€â”€ yt_transcript_utils.py  # Python å·¥å…·è„šæœ¬
```

#### 4. æœ€ä½è¦æ±‚

*   **ä¸Šä¸‹æ–‡**: 4k tokens æ´»è·ƒçª—å£
*   **æ¨ç†**: åˆçº§ (äºŒå…ƒåˆ†ç±»)
*   **æŒ‡ä»¤éµå¾ª**: ä¸­ç­‰ (å•ä¸€çº¦æŸéµå¾ª)
*   **ç›®æ ‡æ¨¡å‹å±‚çº§**: Llama-3-8B (Instruct) / GPT-3.5 Turbo çº§åˆ«ã€‚

#### éŸ³é¢‘åˆ†å‰²ç­–ç•¥

ä¸ºè§„é¿ API é™åˆ¶ï¼ˆ25MBï¼‰å¹¶æé«˜ç¨³å®šæ€§ï¼Œå¯¹å¤§éŸ³é¢‘æ–‡ä»¶è¿›è¡Œæ™ºèƒ½åˆ†å‰²ï¼š
1. **ç²—ç•¥åˆ†å‰²**ï¼šæŒ‰ 10MB é—´éš”è®¡ç®—ç†è®ºåˆ†å‰²ç‚¹ã€‚
2. **é™éŸ³æ£€æµ‹**ï¼šä½¿ç”¨ FFmpeg æ£€æµ‹ç²—ç•¥ç‚¹é™„è¿‘çš„é™éŸ³åŒºé—´ã€‚
3. **æ™ºèƒ½å†³ç­–**ï¼šé€‰æ‹© 60ç§’åå·®èŒƒå›´å†…æœ€è¿‘çš„é™éŸ³ç‚¹ä½œä¸ºå®é™…åˆ†å‰²ä½ç½®ã€‚
4. **å…œåº•æœºåˆ¶**ï¼šè‹¥èŒƒå›´å†…æ— é™éŸ³ï¼Œåˆ™åœ¨ç²—ç•¥ç‚¹å¼ºåˆ¶åˆ†å‰²ã€‚

#### é•¿æ–‡æœ¬å¤„ç†ç­–ç•¥ï¼ˆæ–°å¢ï¼ï¼‰

ä¸ºäº†åœ¨ä¸çªç ´ LLM ä¸Šä¸‹æ–‡é™åˆ¶çš„æƒ…å†µä¸‹å¤„ç†è¶…é•¿è§†é¢‘ï¼ˆå¦‚ >2å°æ—¶ï¼‰ï¼Œæˆ‘ä»¬é‡‡ç”¨äº† **Map-Reduce æ€æƒ³çš„æ··åˆæµæ°´çº¿**ï¼š

1.  **ç»“æ„åŒ–åˆ†å—ï¼ˆè„šæœ¬ï¼‰**ï¼š
    - `chunk-text` å‘½ä»¤æŒ‰å¥å­è¾¹ç•Œå°†åŸå§‹æ–‡æœ¬åˆ‡åˆ†ä¸ºè¯­ä¹‰å—ï¼ˆ~8000å­—ç¬¦ï¼‰ã€‚
    - ä½¿ç”¨å¹‚ç­‰çš„ `manifest.json` è¿½è¸ªçŠ¶æ€ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ã€‚

2.  **ä¸¤é˜¶æ®µç« èŠ‚è§„åˆ’**ï¼š
    - **ä¼˜å…ˆçº§ 1**ï¼šå¦‚æœæœ‰ YouTube ç« èŠ‚ï¼ˆé€šè¿‡ `get-chapters` è·å–ï¼‰ï¼Œç›´æ¥ä½¿ç”¨ã€‚
    - **ä¼˜å…ˆçº§ 2**ï¼šæ— ç« èŠ‚æ—¶ï¼ŒLLM å…ˆå¯¹æ¯ä¸ªå—ç”Ÿæˆæ‘˜è¦ï¼Œå†åŸºäºæ‘˜è¦è§„åˆ’å…¨å±€ç« èŠ‚ç»“æ„ã€‚

3.  **æ— çŠ¶æ€ç¿»è¯‘**ï¼š
    - æ¯ä¸ªæ–‡æœ¬å—ç”± LLM ç‹¬ç«‹ç¿»è¯‘ï¼Œä¸éœ€è¦å…¨å±€ä¸Šä¸‹æ–‡ã€‚
    - æœ€ç»ˆç”±è„šæœ¬ï¼ˆ`merge-content`ï¼‰è´Ÿè´£æŒ‰é¡ºåºç»„è£…å¹¶æ’å…¥ç« èŠ‚æ ‡é¢˜ã€‚

#### ä¸ºä»€ä¹ˆå¤šé“¾æ¥é‡‡ç”¨ä¸²è¡Œå¤„ç†ï¼Ÿ

å¤„ç†å¤šä¸ª YouTube é“¾æ¥æ—¶ï¼Œæœ¬å·¥å…·é‡‡ç”¨**ä¸²è¡Œå¤„ç†**ï¼ˆé€ä¸ªå¤„ç†ï¼‰è€Œéå¹¶è¡Œï¼š

| æ–¹æ¡ˆ | å¯è¡Œæ€§ | åŸå›  |
|------|--------|------|
| å¹¶è¡Œ + Subagent | ä¸æ”¯æŒ | å½“å‰ Claude/Gemini Code æ¶æ„ä¸æ”¯æŒä¸ºé€šç”¨ä»»åŠ¡åˆ›å»ºå…·æœ‰ç‹¬ç«‹ä¸Šä¸‹æ–‡çš„å­æ™ºèƒ½ä½“ |
| å•ä¼šè¯å†…å¹¶è¡Œ | ä¸å¯è¡Œ | AI ä¼˜åŒ–æ­¥éª¤éœ€è¦ LLM ç›´æ¥å‚ä¸ï¼Œæ— æ³•"åˆ†èº«"æˆå¤šä¸ªå¹¶è¡Œè®¤çŸ¥çº¿ç¨‹ |
| ä¸²è¡Œå¤„ç† | é‡‡ç”¨ | å®Œæ•´å¤„ç†ä¸€ä¸ªè§†é¢‘åæ¸…ç†ä¸Šä¸‹æ–‡ï¼Œå†å¤„ç†ä¸‹ä¸€ä¸ª |

### ğŸ“„ è®¸å¯è¯

MIT License

### ğŸ”— ç›¸å…³é“¾æ¥

- [Deepgram API æ–‡æ¡£](https://developers.deepgram.com/)
- [yt-dlp é¡¹ç›®](https://github.com/yt-dlp/yt-dlp)
